{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lPLnCYVTQGk"
      },
      "source": [
        "# Aprendizagem baseada em instâncias - knn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0vfqZ5eEXpFz"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVZ33-HhTUcV"
      },
      "source": [
        "## Base credit data - 98.60%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Wrwt0OWwW2oM"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('credit.pkl', 'rb') as f:\n",
        "  X_credit_treinamento, y_credit_treinamento, X_credit_teste, y_credit_teste = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oVZ2h01W41G",
        "outputId": "450e7e5d-f012-45c7-9e29-70dd7f14f94f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1500, 3), (1500,))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "X_credit_treinamento.shape, y_credit_treinamento.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKtVPiIfW6x6",
        "outputId": "be7a0a16-b145-46b1-99e1-6f7595f0847e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((500, 3), (500,))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "X_credit_teste.shape, y_credit_teste.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkC1VdFmXvcz"
      },
      "outputs": [],
      "source": [
        "knn_credit = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p = 2)\n",
        "knn_credit.fit(X_credit_treinamento, y_credit_treinamento)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSCtq6WKYlFx"
      },
      "outputs": [],
      "source": [
        "previsoes = knn_credit.predict(X_credit_teste)\n",
        "previsoes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeEsIvG6Yq2o"
      },
      "outputs": [],
      "source": [
        "y_credit_teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFRKQkgwYx64",
        "outputId": "4dcbd044-290f-400a-a24f-10983e4cef39"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.986"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "accuracy_score(y_credit_teste, previsoes) # padronização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3L_y8P4ZN2Q"
      },
      "outputs": [],
      "source": [
        "from yellowbrick.classifier import ConfusionMatrix\n",
        "cm = ConfusionMatrix(knn_credit)\n",
        "cm.fit(X_credit_treinamento, y_credit_treinamento)\n",
        "cm.score(X_credit_teste, y_credit_teste)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8yIkbWtZYpG",
        "outputId": "5c410769-3caf-47c2-d253-7928ec9fe087"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       436\n",
            "           1       0.94      0.95      0.95        64\n",
            "\n",
            "    accuracy                           0.99       500\n",
            "   macro avg       0.97      0.97      0.97       500\n",
            "weighted avg       0.99      0.99      0.99       500\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_credit_teste, previsoes))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "9JL8G9jQXTLF",
        "JpDM1Er1obkO",
        "cOSLRdDEsWFx",
        "S_jbxLwqu4fQ",
        "g-23aN-nkDQ7",
        "zr9S1fZXRQhg",
        "2GpcvTQauTVx",
        "QGapZ37jkPAn",
        "K2K3Wu8Q4e0E",
        "mHg2BXJR4hpi",
        "bdNbsNLFkWop",
        "q_KOjDv47-IV",
        "zAecbXOi8AzA",
        "Oi9qbert8aMv",
        "L0FGtQLrnN-0",
        "lmXN77tcnP2v",
        "lnC-s4bLnRmt",
        "PfnUWv8SU7ST",
        "TOCiDpHFU90w",
        "ZO-c0InojFK5",
        "0bLyVMFrjGzm",
        "h8ZVuJ-VDE8h",
        "SN9q4qQiDIsi",
        "0v5iHxzcNPNK",
        "e6tDYDLUNUWH"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}